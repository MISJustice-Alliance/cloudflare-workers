# robots.txt for YWCAOfMissoula.com
# Optimized for both traditional search engines and AI crawlers
# Generated via Cloudflare Worker for dynamic updates

# Default rules for all crawlers
User-agent: *
Allow: /
Disallow: /admin/
Disallow: /api/private/
Disallow: /.well-known/
Disallow: /wp-admin/
Disallow: /wp-includes/
Disallow: /cgi-bin/
Crawl-delay: 1

# Google crawlers
User-agent: Googlebot
Allow: /
Crawl-delay: 1

User-agent: Googlebot-Image
Allow: /
Crawl-delay: 1

User-agent: Googlebot-News
Allow: /

# Google Extended (for AI training)
User-agent: Google-Extended
Allow: /
Crawl-delay: 2

# OpenAI GPTBot (ChatGPT crawler)
User-agent: GPTBot
Allow: /
Crawl-delay: 2
# Allow access for AI understanding of civil rights documentation

# Anthropic Claude-Web (Claude AI crawler)
User-agent: Claude-Web
Allow: /
Crawl-delay: 2
# Allow access for AI assistance with legal advocacy

# Common Crawl (Internet archive and research)
User-agent: CCBot
Allow: /
Crawl-delay: 2
# Allow for archival and research purposes

# Bing crawlers
User-agent: Bingbot
Allow: /
Crawl-delay: 1

User-agent: BingPreview
Allow: /

# Other AI/ML crawlers
User-agent: anthropic-ai
Allow: /
Crawl-delay: 2

User-agent: ChatGPT-User
Allow: /

User-agent: Applebot
Allow: /
Crawl-delay: 1

User-agent: Applebot-Extended
Allow: /
Crawl-delay: 2

# Perplexity AI
User-agent: PerplexityBot
Allow: /
Crawl-delay: 2

# Meta/Facebook crawlers
User-agent: FacebookBot
Allow: /
Crawl-delay: 1

User-agent: facebookexternalhit
Allow: /

# Twitter/X crawler
User-agent: Twitterbot
Allow: /

# LinkedIn crawler
User-agent: LinkedInBot
Allow: /

# Other legitimate search engines
User-agent: DuckDuckBot
Allow: /
Crawl-delay: 1

User-agent: Slurp
# Yahoo
Allow: /
Crawl-delay: 1

User-agent: Baiduspider
Allow: /
Crawl-delay: 2

User-agent: YandexBot
Allow: /
Crawl-delay: 2

# Aggressive/problematic crawlers (more restrictive)
User-agent: AhrefsBot
Crawl-delay: 10
Disallow: /

User-agent: SemrushBot
Crawl-delay: 10
Disallow: /

User-agent: MJ12bot
Crawl-delay: 10
Disallow: /

User-agent: DotBot
Crawl-delay: 10
Disallow: /

User-agent: BLEXBot
Disallow: /

User-agent: MegaIndex
Disallow: /

# Malicious/spam bots (block completely)
User-agent: SiteSnagger
Disallow: /

User-agent: WebZIP
Disallow: /

User-agent: WebCopier
Disallow: /

User-agent: HTTrack
Disallow: /

User-agent: EmailCollector
Disallow: /

User-agent: EmailSiphon
Disallow: /

User-agent: EmailWolf
Disallow: /

User-agent: ExtractorPro
Disallow: /

# AI-specific guidance files
# Note: These are available for AI crawlers to understand site structure
# /llms.txt - AI optimization guide (summary)
# /llms-full.txt - Comprehensive AI content map

# Sitemaps
Sitemap: https://ywcaofmissoula.com/sitemap.xml
Sitemap: https://ywcaofmissoula.com/sitemap-pages.xml
Sitemap: https://ywcaofmissoula.com/sitemap-documents.xml
Sitemap: https://ywcaofmissoula.com/sitemap-timeline.xml

# Host directive (optional, but recommended)
Host: https://ywcaofmissoula.com

# Additional notes:
# - This file can be dynamically generated by Cloudflare Workers
# - Update crawl delays based on server load
# - Monitor crawler behavior and adjust rules as needed
# - Respect AI crawlers that help with legal research and advocacy
# - Block aggressive SEO crawlers that don't provide value
# - Regular review recommended (monthly)
